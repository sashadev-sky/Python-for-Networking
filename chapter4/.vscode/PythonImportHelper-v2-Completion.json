[
    {
        "label": "http.client",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "http.client",
        "description": "http.client",
        "detail": "http.client",
        "documentation": {}
    },
    {
        "label": "httpx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "httpx",
        "description": "httpx",
        "detail": "httpx",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "trio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "trio",
        "description": "trio",
        "detail": "trio",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "urllib.request",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.request",
        "description": "urllib.request",
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "urllib.error",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.error",
        "description": "urllib.error",
        "detail": "urllib.error",
        "documentation": {}
    },
    {
        "label": "urllib.parse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "connection",
        "kind": 5,
        "importPath": "http.client.http_client",
        "description": "http.client.http_client",
        "peekOfCode": "connection = http.client.HTTPConnection(\"www.google.com\")\nconnection.request(\"GET\", \"/\")\nresponse = connection.getresponse()\nprint(type(response))\nprint(response.status, response.reason)\nif response.status == 200:\n    data = response.read()\n    print(data)",
        "detail": "http.client.http_client",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "http.client.http_client",
        "description": "http.client.http_client",
        "peekOfCode": "response = connection.getresponse()\nprint(type(response))\nprint(response.status, response.reason)\nif response.status == 200:\n    data = response.read()\n    print(data)",
        "detail": "http.client.http_client",
        "documentation": {}
    },
    {
        "label": "\t\tresponse",
        "kind": 5,
        "importPath": "httpx_request.httpx_asyncio_http2",
        "description": "httpx_request.httpx_asyncio_http2",
        "peekOfCode": "\t\tresponse = await client.get(\"https://www.google.es\")\n\t\tprint(response)\n\t\tprint(response.http_version)  # HTTP/2\nasyncio.run(resquest_http2())\n\"\"\"\nUsing the HTTP/2 version, which indicates that you can handle multiple requests\nconcurrently from a TCP stream.\nNeed to install the http2 extension using the following command:\n>>> pip3 install httpx[http2]\n\"\"\"",
        "detail": "httpx_request.httpx_asyncio_http2",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "httpx_request.httpx_basic",
        "description": "httpx_request.httpx_basic",
        "peekOfCode": "client = httpx.Client(timeout=10.0)\nresponse = client.get(\"http://www.google.es\")\nprint(response)\nprint(response.status_code)\nprint(response.text)",
        "detail": "httpx_request.httpx_basic",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "httpx_request.httpx_basic",
        "description": "httpx_request.httpx_basic",
        "peekOfCode": "response = client.get(\"http://www.google.es\")\nprint(response)\nprint(response.status_code)\nprint(response.text)",
        "detail": "httpx_request.httpx_basic",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "httpx_request.httpx_http2_trio",
        "description": "httpx_request.httpx_http2_trio",
        "peekOfCode": "results = {}\nasync def fetch_result(client, url, results):\n    print(url)\n    results[url] = await client.get(url)\nasync def main_parallel_requests():\n\tasync with httpx.AsyncClient(http2=True) as client:\n\t\tasync with trio.open_nursery() as nursey:\n\t\t\tfor i in range(2000, 2020):\n\t\t\t\turl = f\"https://en.wikipedia.org/wiki/{i}\"\n\t\t\t\tnursey.start_soon(fetch_result, client, url, results)",
        "detail": "httpx_request.httpx_http2_trio",
        "documentation": {}
    },
    {
        "label": "\t\t\t\turl",
        "kind": 5,
        "importPath": "httpx_request.httpx_http2_trio",
        "description": "httpx_request.httpx_http2_trio",
        "peekOfCode": "\t\t\t\turl = f\"https://en.wikipedia.org/wiki/{i}\"\n\t\t\t\tnursey.start_soon(fetch_result, client, url, results)\ntrio.run(main_parallel_requests)\nprint(results)\n\"\"\"\n$ p3 httpx_http2_trio.py\nhttps://en.wikipedia.org/wiki/2000\nhttps://en.wikipedia.org/wiki/2001\nhttps://en.wikipedia.org/wiki/2002\nhttps://en.wikipedia.org/wiki/2003",
        "detail": "httpx_request.httpx_http2_trio",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "requests_request.get_images_links_url",
        "description": "requests_request.get_images_links_url",
        "peekOfCode": "url = input(\"Enter URL > \")\nvar = requests.get(url).text\nprint(\"Images:\")\nprint(\"#########################\")\nfor image in re.findall(\"<img (.*)>\", var):\n    for images in image.split():\n        if re.findall(\"src=(.*)\", images):\n            image = images[:-1].replace(\"src=\\\"\", \"\")\n            if(image.startswith(\"http\")):\n                print(image)",
        "detail": "requests_request.get_images_links_url",
        "documentation": {}
    },
    {
        "label": "var",
        "kind": 5,
        "importPath": "requests_request.get_images_links_url",
        "description": "requests_request.get_images_links_url",
        "peekOfCode": "var = requests.get(url).text\nprint(\"Images:\")\nprint(\"#########################\")\nfor image in re.findall(\"<img (.*)>\", var):\n    for images in image.split():\n        if re.findall(\"src=(.*)\", images):\n            image = images[:-1].replace(\"src=\\\"\", \"\")\n            if(image.startswith(\"http\")):\n                print(image)\n            else:",
        "detail": "requests_request.get_images_links_url",
        "documentation": {}
    },
    {
        "label": "domain",
        "kind": 5,
        "importPath": "requests_request.requests_headers",
        "description": "requests_request.requests_headers",
        "peekOfCode": "domain = input('Enter the hostname http://')\nresponse = requests.get(f'http://{domain}')\nprint(response.json)\nprint(f'Status code: {response.status_code}')\nprint()\nprint('Headers response: ')\nfor header, value in response.headers.items():\n  print(header, '-->', value)\nprint()\nprint('Headers request: ')",
        "detail": "requests_request.requests_headers",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "requests_request.requests_headers",
        "description": "requests_request.requests_headers",
        "peekOfCode": "response = requests.get(f'http://{domain}')\nprint(response.json)\nprint(f'Status code: {response.status_code}')\nprint()\nprint('Headers response: ')\nfor header, value in response.headers.items():\n  print(header, '-->', value)\nprint()\nprint('Headers request: ')\nfor header, value in response.request.headers.items():",
        "detail": "requests_request.requests_headers",
        "documentation": {}
    },
    {
        "label": "charset",
        "kind": 5,
        "importPath": "requests_request.requests_headers_keys",
        "description": "requests_request.requests_headers_keys",
        "peekOfCode": "charset = utf-8\nX-Frame-Options: DENY\nVia: 1.1 vegur, 1.1 varnish, 1.1 varnish\nAccept-Ranges: bytes\nDate: Tue, 11 May 2021 08: 10: 29 GMT\nAge: 348\nX-Served-By: cache-bwi5132-BWI, cache-ewr18165-EWR\nX-Cache: HIT, HIT\nX-Cache-Hits: 1, 1\nX-Timer: S1620720629.373086, VS0, VE0",
        "detail": "requests_request.requests_headers_keys",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "requests_request.testing_api_rest_get_method",
        "description": "requests_request.testing_api_rest_get_method",
        "peekOfCode": "response = requests.get(\"http://httpbin.org/get\", timeout=5)\nprint(\"HTTP Status Code: \" + str(response.status_code))\nprint(response.headers)\nif response.status_code == 200:\n    results = response.json()\n    for result in results.items():\n\t    print(result)\n    print()\n    print(\"Headers response: \")\n    for header, value in response.headers.items():",
        "detail": "requests_request.testing_api_rest_get_method",
        "documentation": {}
    },
    {
        "label": "count_words_file",
        "kind": 2,
        "importPath": "urllib.request.count_words_file",
        "description": "urllib.request.count_words_file",
        "peekOfCode": "def count_words_file(url):\n    try:\n        file_response = urllib.request.urlopen(url)\n    except urllib.error.URLError as error:\n        print('Exception', error)\n        print('reason', error.reason)\n    else:\n        content = file_response.read()\n        return len(content.split())\nprint(count_words_file('https://www.gutenberg.org/cache/epub/2000/pg2000.txt'))",
        "detail": "urllib.request.count_words_file",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "urllib.request.download_file",
        "description": "urllib.request.download_file",
        "peekOfCode": "url = 'https://www.python.org/static/img/python-logo.png'\n# download file with urlretrieve\nurllib.request.urlretrieve(url, 'python.png')\n# download file with urlopen\nwith urllib.request.urlopen(url) as response:\n    print(\"Status:\", response.status)\n    print(\"Downloading python.png\")\n    with open(\"python.png\", \"wb\" ) as image:\n        image.write(response.read())\n\"\"\"",
        "detail": "urllib.request.download_file",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "urllib.request.get_emails_url_request",
        "description": "urllib.request.get_emails_url_request",
        "peekOfCode": "USER_AGENT = 'Mozilla/5.0 (Linux; Android 10) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.101 Mobile Safari/537.36'\nurl =  input(\"Enter url: http://\")\n#https://www.packtpub.com/about/terms-and-conditions\nopener = urllib.request.build_opener()\nopener.addheaders = [('User-agent', USER_AGENT)]\nurllib.request.install_opener(opener)\nresponse = urllib.request.urlopen(f'http://{url}')\nhtml_content= response.read()\npattern = re.compile(\"[-a-zA-Z0-9._]+[-a-zA-Z0-9._]+@[-a-zA-Z0-9_]+.[a-zA-Z0-9_.]+\")\nmails = re.findall(pattern,str(html_content))",
        "detail": "urllib.request.get_emails_url_request",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "urllib.request.get_emails_url_request",
        "description": "urllib.request.get_emails_url_request",
        "peekOfCode": "url =  input(\"Enter url: http://\")\n#https://www.packtpub.com/about/terms-and-conditions\nopener = urllib.request.build_opener()\nopener.addheaders = [('User-agent', USER_AGENT)]\nurllib.request.install_opener(opener)\nresponse = urllib.request.urlopen(f'http://{url}')\nhtml_content= response.read()\npattern = re.compile(\"[-a-zA-Z0-9._]+[-a-zA-Z0-9._]+@[-a-zA-Z0-9_]+.[a-zA-Z0-9_.]+\")\nmails = re.findall(pattern,str(html_content))\nprint(mails)",
        "detail": "urllib.request.get_emails_url_request",
        "documentation": {}
    },
    {
        "label": "opener",
        "kind": 5,
        "importPath": "urllib.request.get_emails_url_request",
        "description": "urllib.request.get_emails_url_request",
        "peekOfCode": "opener = urllib.request.build_opener()\nopener.addheaders = [('User-agent', USER_AGENT)]\nurllib.request.install_opener(opener)\nresponse = urllib.request.urlopen(f'http://{url}')\nhtml_content= response.read()\npattern = re.compile(\"[-a-zA-Z0-9._]+[-a-zA-Z0-9._]+@[-a-zA-Z0-9_]+.[a-zA-Z0-9_.]+\")\nmails = re.findall(pattern,str(html_content))\nprint(mails)\n\"\"\"\n$ p3 get_emails_url_request.py",
        "detail": "urllib.request.get_emails_url_request",
        "documentation": {}
    },
    {
        "label": "opener.addheaders",
        "kind": 5,
        "importPath": "urllib.request.get_emails_url_request",
        "description": "urllib.request.get_emails_url_request",
        "peekOfCode": "opener.addheaders = [('User-agent', USER_AGENT)]\nurllib.request.install_opener(opener)\nresponse = urllib.request.urlopen(f'http://{url}')\nhtml_content= response.read()\npattern = re.compile(\"[-a-zA-Z0-9._]+[-a-zA-Z0-9._]+@[-a-zA-Z0-9_]+.[a-zA-Z0-9_.]+\")\nmails = re.findall(pattern,str(html_content))\nprint(mails)\n\"\"\"\n$ p3 get_emails_url_request.py\nEnter url: http://www.packtpub.com/about/terms-and-conditions",
        "detail": "urllib.request.get_emails_url_request",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "urllib.request.get_emails_url_request",
        "description": "urllib.request.get_emails_url_request",
        "peekOfCode": "response = urllib.request.urlopen(f'http://{url}')\nhtml_content= response.read()\npattern = re.compile(\"[-a-zA-Z0-9._]+[-a-zA-Z0-9._]+@[-a-zA-Z0-9_]+.[a-zA-Z0-9_.]+\")\nmails = re.findall(pattern,str(html_content))\nprint(mails)\n\"\"\"\n$ p3 get_emails_url_request.py\nEnter url: http://www.packtpub.com/about/terms-and-conditions\n['nr@context', 'nr@original', 'customercare@packt.com', 'customercare@packt', 'customercare@packt', 'subscription.support@packt.com', 'subscription.support@packt.com', 'customercare@packt', 'customercare@packt']\n\"\"\"",
        "detail": "urllib.request.get_emails_url_request",
        "documentation": {}
    },
    {
        "label": "pattern",
        "kind": 5,
        "importPath": "urllib.request.get_emails_url_request",
        "description": "urllib.request.get_emails_url_request",
        "peekOfCode": "pattern = re.compile(\"[-a-zA-Z0-9._]+[-a-zA-Z0-9._]+@[-a-zA-Z0-9_]+.[a-zA-Z0-9_.]+\")\nmails = re.findall(pattern,str(html_content))\nprint(mails)\n\"\"\"\n$ p3 get_emails_url_request.py\nEnter url: http://www.packtpub.com/about/terms-and-conditions\n['nr@context', 'nr@original', 'customercare@packt.com', 'customercare@packt', 'customercare@packt', 'subscription.support@packt.com', 'subscription.support@packt.com', 'customercare@packt', 'customercare@packt']\n\"\"\"",
        "detail": "urllib.request.get_emails_url_request",
        "documentation": {}
    },
    {
        "label": "mails",
        "kind": 5,
        "importPath": "urllib.request.get_emails_url_request",
        "description": "urllib.request.get_emails_url_request",
        "peekOfCode": "mails = re.findall(pattern,str(html_content))\nprint(mails)\n\"\"\"\n$ p3 get_emails_url_request.py\nEnter url: http://www.packtpub.com/about/terms-and-conditions\n['nr@context', 'nr@original', 'customercare@packt.com', 'customercare@packt', 'customercare@packt', 'subscription.support@packt.com', 'subscription.support@packt.com', 'customercare@packt', 'customercare@packt']\n\"\"\"",
        "detail": "urllib.request.get_emails_url_request",
        "documentation": {}
    },
    {
        "label": "chrome_user_agent",
        "kind": 2,
        "importPath": "urllib.request.get_headers_response_request",
        "description": "urllib.request.get_headers_response_request",
        "peekOfCode": "def chrome_user_agent():\n    opener = urllib.request.build_opener()\n    opener.addheaders = [('User-agent', USER_AGENT)]\n    urllib.request.install_opener(opener)\n    response = urllib.request.urlopen(url)\n    print(\"Response headers\")\n    print(\"--------------------\")\n    for header,value in response.getheaders():\n        print(header + \":\" + value)\n    request = Request(url)",
        "detail": "urllib.request.get_headers_response_request",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "urllib.request.get_headers_response_request",
        "description": "urllib.request.get_headers_response_request",
        "peekOfCode": "url = 'http://python.org'\nUSER_AGENT = 'Mozilla/5.0 (Linux; Android 10) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.101 Mobile Safari/537.36'\ndef chrome_user_agent():\n    opener = urllib.request.build_opener()\n    opener.addheaders = [('User-agent', USER_AGENT)]\n    urllib.request.install_opener(opener)\n    response = urllib.request.urlopen(url)\n    print(\"Response headers\")\n    print(\"--------------------\")\n    for header,value in response.getheaders():",
        "detail": "urllib.request.get_headers_response_request",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "urllib.request.get_headers_response_request",
        "description": "urllib.request.get_headers_response_request",
        "peekOfCode": "USER_AGENT = 'Mozilla/5.0 (Linux; Android 10) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.101 Mobile Safari/537.36'\ndef chrome_user_agent():\n    opener = urllib.request.build_opener()\n    opener.addheaders = [('User-agent', USER_AGENT)]\n    urllib.request.install_opener(opener)\n    response = urllib.request.urlopen(url)\n    print(\"Response headers\")\n    print(\"--------------------\")\n    for header,value in response.getheaders():\n        print(header + \":\" + value)",
        "detail": "urllib.request.get_headers_response_request",
        "documentation": {}
    },
    {
        "label": "data_dictionary",
        "kind": 5,
        "importPath": "urllib.request.urllib_post_request",
        "description": "urllib.request.urllib_post_request",
        "peekOfCode": "data_dictionary = {'id': '0123456789'}\ndata = urllib.parse.urlencode(data_dictionary)\ndata = data.encode('ascii')\n\"\"\"\nthe urlopen() method returns an instance of the http.client.HTTPResponse class.\n\"\"\"\nwith urllib.request.urlopen('http://httpbin.org/post', data) as response:\n\tprint(response.read().decode())\n\"\"\"\n$ p3 urllib_post_request.py",
        "detail": "urllib.request.urllib_post_request",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "urllib.request.urllib_post_request",
        "description": "urllib.request.urllib_post_request",
        "peekOfCode": "data = urllib.parse.urlencode(data_dictionary)\ndata = data.encode('ascii')\n\"\"\"\nthe urlopen() method returns an instance of the http.client.HTTPResponse class.\n\"\"\"\nwith urllib.request.urlopen('http://httpbin.org/post', data) as response:\n\tprint(response.read().decode())\n\"\"\"\n$ p3 urllib_post_request.py\n{",
        "detail": "urllib.request.urllib_post_request",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "urllib.request.urllib_post_request",
        "description": "urllib.request.urllib_post_request",
        "peekOfCode": "data = data.encode('ascii')\n\"\"\"\nthe urlopen() method returns an instance of the http.client.HTTPResponse class.\n\"\"\"\nwith urllib.request.urlopen('http://httpbin.org/post', data) as response:\n\tprint(response.read().decode())\n\"\"\"\n$ p3 urllib_post_request.py\n{\n  \"args\": {},",
        "detail": "urllib.request.urllib_post_request",
        "documentation": {}
    }
]